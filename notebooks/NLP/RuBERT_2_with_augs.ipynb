{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "YkimRgK-xooA",
   "metadata": {
    "id": "YkimRgK-xooA"
   },
   "source": [
    "# DL. RuBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vn9FgAUYcY8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vn9FgAUYcY8c",
    "outputId": "f5c9f7ac-7ebd-4e36-bc19-ee55bb5500e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install transformers -q\n",
    "!pip install torch -q\n",
    "!pip install scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1313cd10-f6d3-4e39-a1f1-c63504cf49e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "z4qphqXfkdeH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4qphqXfkdeH",
    "outputId": "b8cfbcf5-2f6b-4347-dbde-081be0e58d34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy3 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cfa9519-809a-4d05-9f13-9db6f53fbf7d",
   "metadata": {
    "id": "4cfa9519-809a-4d05-9f13-9db6f53fbf7d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import warnings\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f4cffc-69bb-4df8-9e0c-417fab5cf7a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15f4cffc-69bb-4df8-9e0c-417fab5cf7a2",
    "outputId": "732a9c59-131d-4153-bfcb-1fbba69b9e77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10272, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('labelled_data_1.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hwuw69iUhrfN",
   "metadata": {
    "id": "hwuw69iUhrfN"
   },
   "outputs": [],
   "source": [
    "df = df[(~df.cluster.isna())&(df.cluster != '?')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wc7qR6T2x45z",
   "metadata": {
    "id": "Wc7qR6T2x45z"
   },
   "source": [
    "## Базовая предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62GdMh-ThMeP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "62GdMh-ThMeP",
    "outputId": "bdfd816b-5763-46e0-f244-903181132402"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theme</th>\n",
       "      <th>processed_theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Жалоба абонента  TT20595877</td>\n",
       "      <td>жалоба абонент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Жалоба абонента  TT20592639</td>\n",
       "      <td>жалоба абонент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Жалоба абонента  TT20594559</td>\n",
       "      <td>жалоба абонент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Жалоба абонента  TT20593507</td>\n",
       "      <td>жалоба абонент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Жалоба абонента  TT20593899</td>\n",
       "      <td>жалоба абонент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Re: [Ticket#10276498] Уведомление.Сбой на стор...</td>\n",
       "      <td>уведомление сбой на сторона оператор теле2-каз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ЧС по 99993 от 01.01.2023</td>\n",
       "      <td>черный список</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Жалоба абонента  TT20595548</td>\n",
       "      <td>жалоба абонент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Жалоба абонента  TT20598328</td>\n",
       "      <td>жалоба абонент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Жалоба абонента  TT20591891</td>\n",
       "      <td>жалоба абонент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>отключение</td>\n",
       "      <td>отключение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Жалоба TT20600601</td>\n",
       "      <td>жалоба</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ЧС по 99993 от 02.01.2023</td>\n",
       "      <td>черный список</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Жалоба абонента  TT20604112</td>\n",
       "      <td>жалоба абонент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Not Provided</td>\n",
       "      <td>айти</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sim reminder</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Жалоба абонента  TT20603820</td>\n",
       "      <td>жалоба абонент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ЧС по 99993 от 03.01.2023</td>\n",
       "      <td>черный список</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Жалоба абонента  TT20604112</td>\n",
       "      <td>жалоба абонент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Жалоба абонента  TT20605734</td>\n",
       "      <td>жалоба абонент</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                theme  \\\n",
       "0                         Жалоба абонента  TT20595877   \n",
       "1                         Жалоба абонента  TT20592639   \n",
       "2                         Жалоба абонента  TT20594559   \n",
       "3                         Жалоба абонента  TT20593507   \n",
       "4                         Жалоба абонента  TT20593899   \n",
       "5   Re: [Ticket#10276498] Уведомление.Сбой на стор...   \n",
       "6                           ЧС по 99993 от 01.01.2023   \n",
       "7                         Жалоба абонента  TT20595548   \n",
       "8                         Жалоба абонента  TT20598328   \n",
       "9                         Жалоба абонента  TT20591891   \n",
       "10                                         отключение   \n",
       "11                                  Жалоба TT20600601   \n",
       "12                          ЧС по 99993 от 02.01.2023   \n",
       "14                        Жалоба абонента  TT20604112   \n",
       "15                                       Not Provided   \n",
       "16                                       Sim reminder   \n",
       "17                        Жалоба абонента  TT20603820   \n",
       "18                          ЧС по 99993 от 03.01.2023   \n",
       "19                        Жалоба абонента  TT20604112   \n",
       "20                        Жалоба абонента  TT20605734   \n",
       "\n",
       "                                      processed_theme  \n",
       "0                                      жалоба абонент  \n",
       "1                                      жалоба абонент  \n",
       "2                                      жалоба абонент  \n",
       "3                                      жалоба абонент  \n",
       "4                                      жалоба абонент  \n",
       "5   уведомление сбой на сторона оператор теле2-каз...  \n",
       "6                                       черный список  \n",
       "7                                      жалоба абонент  \n",
       "8                                      жалоба абонент  \n",
       "9                                      жалоба абонент  \n",
       "10                                         отключение  \n",
       "11                                             жалоба  \n",
       "12                                      черный список  \n",
       "14                                     жалоба абонент  \n",
       "15                                               айти  \n",
       "16                                                     \n",
       "17                                     жалоба абонент  \n",
       "18                                      черный список  \n",
       "19                                     жалоба абонент  \n",
       "20                                     жалоба абонент  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy3\n",
    "import re\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "replacement_dict = {\n",
    "    'provider': 'провайдер',\n",
    "    'esim': 'есим',\n",
    "    'b2b': 'б2б',\n",
    "    'b2c': 'б2с',\n",
    "    'invoice': 'инвойс',\n",
    "    'tele2': 'теле2',\n",
    "    'mts': 'мтс',\n",
    "    'sim': 'сим',\n",
    "    'sim-карта': 'сим-карта',\n",
    "    'server': 'сервер',\n",
    "    'sms': 'смс',\n",
    "    'vimpelcom': 'вымпелком',\n",
    "    'whatsapp': 'ватсапп',\n",
    "    'message': 'сообщение',\n",
    "    'access': 'доступ',\n",
    "    'team': 'команда',\n",
    "    'systems': 'система',\n",
    "    'delivery': 'доставка',\n",
    "    'diagnostic': 'диагностика',\n",
    "    'information': 'информация',\n",
    "    'help': 'помощь',\n",
    "    'wd': 'вд',\n",
    "    'ru': 'ру',\n",
    "    'mobile': 'мобильный',\n",
    "    'mailbox': 'мэилбокс',\n",
    "    'sim-меню': 'сим-меню',\n",
    "    'id': 'айди',\n",
    "    'snminakovabeeline': 'билайн',\n",
    "    'beeline': 'билайн',\n",
    "    'iphone': 'айфон',\n",
    "    'gprs': 'грпс',\n",
    "    'ltmobidsupportmts': 'мтс',\n",
    "    'team': 'команда',\n",
    "    '-2024просьба': 'просьба',\n",
    "    'эл': 'электронный'\n",
    "}\n",
    "\n",
    "\n",
    "def process_text(text):\n",
    "    text = re.sub(r'\\s*TT\\d{8}', '', text)\n",
    "\n",
    "    for eng_word, rus_word in replacement_dict.items():\n",
    "        text = text.replace(eng_word.lower(), rus_word)\n",
    "\n",
    "    if 'ЧС' in text:\n",
    "        return 'черный список'\n",
    "    if 'зарегистрировано обращение' in text.lower():\n",
    "        return 'регистрация обращения'\n",
    "\n",
    "    text = re.sub(r'[A-Za-z]', '', text)\n",
    "    text = re.sub(r'[^\\w\\s-]', ' ', text)\n",
    "\n",
    "    words = text.lower().split()\n",
    "    normalized_words = [morph.parse(word)[0].normal_form for word in words if re.search(r'[а-яё]', word)]\n",
    "\n",
    "    return ' '.join(normalized_words)\n",
    "\n",
    "df['processed_theme'] = df['theme'].apply(process_text)\n",
    "df[['theme', 'processed_theme']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "YnKPnZjnhCBW",
   "metadata": {
    "id": "YnKPnZjnhCBW"
   },
   "outputs": [],
   "source": [
    "class RuBertCleaner:\n",
    "    def __init__(self):\n",
    "        self.phone_pattern = re.compile(r'^((8|\\+7)[\\- ]?)?(\\(?\\d{3}\\)?[\\- ]?)?[\\d\\- ]{7,10}$')\n",
    "        self.name_pattern = re.compile(r'\\b[А-ЯЁ][а-яё]+\\s[А-ЯЁ][а-яё]+\\b')\n",
    "        self.sim_card_pattern = re.compile(r'\\bсим-карт\\w*\\b')\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            return ''\n",
    "        text = self.phone_pattern.sub('номер телефона', text)\n",
    "        text = self.name_pattern.sub('фио', text)\n",
    "        text = self.sim_card_pattern.sub('сим-карта', text)\n",
    "        text = re.sub(r'(?<![\\w])\\d+(?![\\w])', '', text)\n",
    "        text = re.sub(r'\\s-\\s', ' ', text)\n",
    "        text = re.sub(r'(?<!\\S)-|-(?!\\S)', '', text)\n",
    "        return text.strip()\n",
    "\n",
    "cleaner = RuBertCleaner()\n",
    "df[\"text_clean\"] = df[\"descr\"].apply(cleaner.clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IiP8xT7_x9ZD",
   "metadata": {
    "id": "IiP8xT7_x9ZD"
   },
   "source": [
    "##  Применение pretrained модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "k193uHZ-m79f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98,
     "referenced_widgets": [
      "aadf25cf212e404fa966bd179155a9da",
      "a7c8fd44340941f58aca2e6e4667542a",
      "1672ec73224046edbc90abf252695624",
      "293d013bc99749ea998986879055cde7",
      "7e228d735a2e482da39fba5e09ba2ec1",
      "aa83b6284913405791bb7daa88aa1503",
      "bea8d004d9bd4d0aa91761ca18877236",
      "1890cb56df794924a8ed81c5298253e0",
      "8d1b6aeae89f4365a2bf5c16d49d55aa",
      "0abfd6fed98e4c31b56d4ab95207fa32",
      "2185fd7c5dea4cf197ccd9047471fb95",
      "8808368c92b1447eb10b0e2e293284cd",
      "8f872c0a470049529f822d8af0c4c334",
      "30bbb3ed344841288a84584625039a2d",
      "3adcf586df5c45dfaac4bf506fa58e49",
      "f25bb29bc85a4bcf93fd371ba935b22e",
      "98074819994847bf8998e82c29344c6d",
      "330f3b2765cb4f30b31bab37737e5958",
      "078e9e4e25fd4c27aca916edc06c0d3a",
      "ad53f3a0496d41d6a3f0beb0aa741bfe",
      "e925deec27d24992a59c66d1a8e8290a",
      "9052a2169eee435ca74a3af915afa3f1"
     ]
    },
    "id": "k193uHZ-m79f",
    "outputId": "2dce98c8-1704-441a-e01c-0f1ce97caedc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9749580e54a24fb5a9d04b6750ec81d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/590 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7a34ae873a446a9d9110437111c32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/1.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "df_clean = df[df[\"cluster\"] != \"?\"].copy()\n",
    "df_clean[\"text\"] = (\n",
    "    df_clean[\"sender_name\"].fillna('') + \" \" +\n",
    "    df_clean[\"theme\"].fillna('') + \" \" +\n",
    "    df_clean[\"text_clean\"].fillna('')\n",
    ").str.strip()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_clean[\"label\"] = label_encoder.fit_transform(df_clean[\"cluster\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_clean[\"text\"].values,\n",
    "    df_clean[\"label\"].values,\n",
    "    test_size=0.25,\n",
    "    stratify=df_clean[\"label\"].values,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"sberbank-ai/ruBert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_texts(X_train)\n",
    "test_encodings = tokenize_texts(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LuBsjL-5oRre",
   "metadata": {
    "id": "LuBsjL-5oRre"
   },
   "source": [
    "Помогла статья: https://habr.com/ru/articles/682476/\n",
    "\n",
    "Создадим класс для нашего датасета, затем обучим модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2qjZX5-n0Gb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "c83bb25f8216474ea32a769b5236547f",
      "ed10f0596e494f84a88b7833ba60e35d",
      "207f5481d0b34525bacd4bd136a6e73b",
      "ec751176ba9546c082591ba7963f4dbd",
      "d79189d3bf2e42438e45e19958954602",
      "493797452b0f4997a9660cb77e708cee",
      "954574159d3e4d34ba7e8b23a1d68117",
      "5b55627606984d17b4be67e38132ccf0",
      "5ec6ee507884454dbca1669db4d71b14",
      "6a57cab76d5a4d50a693afd5bbd2dc96",
      "0e6a2ed95dbd4d85a90a1e5e0e83d390"
     ]
    },
    "id": "f2qjZX5-n0Gb",
    "outputId": "3309a72d-ec20-40d4-fc95-1c07543aea9f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8189f0915aa14bb7b9290a0b38b3d3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/716M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sberbank-ai/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class TicketDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TicketDataset(train_encodings, y_train)\n",
    "test_dataset = TicketDataset(test_encodings, y_test)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(label_encoder.classes_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "UqA-FaSip-L6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqA-FaSip-L6",
    "outputId": "757a2ff5-50c8-4012-9695-d09cffb20029"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████| 473/473 [03:50<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss = 57.6107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|███████████████████████████████████████████████████████████████████████| 473/473 [04:16<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train loss = 23.8263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████████████████████████████████████████████████████████| 473/473 [04:08<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train loss = 12.8517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|███████████████████████████████████████████████████████████████████████| 473/473 [04:10<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train loss = 7.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "epochs = 4\n",
    "batch_size = 16\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: train loss = {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "WYR0pcwTw3fM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYR0pcwTw3fM",
    "outputId": "c74ad161-3b28-4a28-c6a5-66a9fa56ba5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total inference time: 34.10 seconds\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # оценка\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_logits = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "        all_logits.extend(logits.cpu().numpy())\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n Total inference time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "FdW80dpcxKc0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdW80dpcxKc0",
    "outputId": "7c595b89-1eba-4164-a239-2e1c2b428686"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9992\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "all_probs = F.softmax(torch.tensor(all_logits), dim=1).numpy()\n",
    "\n",
    "print(f\"ROC AUC: {roc_auc_score(all_labels, all_probs, multi_class='ovr'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "TlBmlkoEwuOt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlBmlkoEwuOt",
    "outputId": "89623299-8baf-4e6c-cce5-906e719b0298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      1024\n",
      "          10       0.98      0.96      0.97        93\n",
      "           2       0.93      1.00      0.97        43\n",
      "           3       0.98      0.98      0.98       107\n",
      "           4       0.98      0.97      0.98       483\n",
      "           5       0.94      0.95      0.95       123\n",
      "           6       0.98      0.98      0.98       182\n",
      "           7       0.95      0.98      0.96        83\n",
      "           8       0.99      0.98      0.98        81\n",
      "           9       0.99      1.00      1.00       299\n",
      "\n",
      "    accuracy                           0.99      2518\n",
      "   macro avg       0.97      0.98      0.98      2518\n",
      "weighted avg       0.99      0.99      0.99      2518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nclassification_report:\")\n",
    "\n",
    "target_names = [str(cls) for cls in label_encoder.classes_]\n",
    "print(classification_report(all_labels, all_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8hUPVNK3hZKK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hUPVNK3hZKK",
    "outputId": "ad66ba4d-63e7-4573-aabf-8d130b588dd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/content/rb_tokenizer/tokenizer_config.json',\n",
       " '/content/rb_tokenizer/special_tokens_map.json',\n",
       " '/content/rb_tokenizer/vocab.txt',\n",
       " '/content/rb_tokenizer/added_tokens.json',\n",
       " '/content/rb_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"/content/rb_model\")\n",
    "tokenizer.save_pretrained(\"/content/rb_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8GnKvcKchxWG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8GnKvcKchxWG",
    "outputId": "ec2a34de-5774-4700-af0e-e58a2630bcbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sberbank-ai/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"/content/tr_rb_model.pth\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(label_encoder.classes_))\n",
    "model.load_state_dict(torch.load(\"/content/tr_rb_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "XKhDEh2rjsgX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKhDEh2rjsgX",
    "outputId": "a7fb1622-a824-4eb5-99ef-8d053bb15146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e4a1c6-c69e-4ba4-bba8-baef3276a145",
   "metadata": {
    "id": "85e4a1c6-c69e-4ba4-bba8-baef3276a145"
   },
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd5679-112c-4543-9c44-833c1fb29cf3",
   "metadata": {
    "id": "40fd5679-112c-4543-9c44-833c1fb29cf3"
   },
   "source": [
    "После бустингов, которые уже дали отличный результат, опробовали предобученный rubert.\n",
    "Оценка моделей выполнена с помощью метрик ROC AUC, precision, recall, f1-score и accuracy.\n",
    "\n",
    "- Logistic Regression: 0.908\n",
    "- SVC: 0.935\n",
    "- CatBoost: 0.984\n",
    "- Optuna + CatBoost: 0.982\n",
    "- XGBoost:  0.971\n",
    "- Optuna + XGBoost: 0.968\n",
    "- Lightgbm: 0.981\n",
    "- Optuna + Lightgbm: 0.982\n",
    "- RuBERT:  0.998 \\\n",
    "RuBERT показала наилучшее качество по метрике ROC AUC, немного превосходя бустинги.\n",
    "\n",
    "Сравнение по метрике accuracy (доля правильных ответов)\n",
    "- Logistic Regression: 0.70\n",
    "- SVC: 0.75\n",
    "- CatBoost: 0.88\n",
    "- Optuna + CatBoost: 0.88\n",
    "- XGBoost: 0.86\n",
    "- Optuna + XGBoost: 0.86\n",
    "- Lightgbm: 0.87\n",
    "- Optuna + Lightgbm: 0.87\n",
    "- RuBERT: 0.97\\\n",
    "RuBERT показала наивысшую точность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb00290e-3cd8-4819-bdad-6936b1b244ab",
   "metadata": {},
   "source": [
    "### Аугментация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d5834e6-de6d-4b9e-a26c-e4425888c445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b65b90bdc34100a54ab38f7868439b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09ae03a2bb0461f837887daadd3d2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167bd9514d944eed962a3ec7f29b3d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/803k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4402ddbf7058491a945857318d6f181f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.60M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5530ad5956496fad6a724dc6338d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c58196cf9ea4c45be9b99a51596c478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9184949da249d48997bc81d9b88865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/307M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27d353cc6ef4e36bf62c4f90c7f8e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cache_dir = \"/home/transformers_files/\"\n",
    "cache_dir_models = cache_dir + \"default_models/\"\n",
    "cache_dir_tokenizers = cache_dir + \"tokenizers/\"\n",
    "ru_en_model_name = 'Helsinki-NLP/opus-mt-ru-en'\n",
    "\n",
    "ru_en_tokenizer = MarianTokenizer.from_pretrained(ru_en_model_name, cache_dir=cache_dir_tokenizers)\n",
    "ru_en_model = MarianMTModel.from_pretrained(ru_en_model_name, cache_dir=cache_dir_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b0116c1-753b-45cb-abb6-413f9603f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/home/transformers_files/\"\n",
    "cache_dir_models = cache_dir + \"default_models/\"\n",
    "cache_dir_tokenizers = cache_dir + \"tokenizers/\"\n",
    "\n",
    "en_ru_model_name = 'Helsinki-NLP/opus-mt-en-ru'\n",
    "en_ru_tokenizer = MarianTokenizer.from_pretrained(ru_en_model_name, cache_dir=cache_dir_tokenizers)\n",
    "en_ru_model = MarianMTModel.from_pretrained(ru_en_model_name, cache_dir=cache_dir_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3dd1cee6-8ba7-48d8-8074-06a779108052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(62518, 512, padding_idx=62517)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(62518, 512, padding_idx=62517)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLU()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(62518, 512, padding_idx=62517)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLU()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=62518, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ru_en_model.to(device)\n",
    "en_ru_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72167e94-2142-4419-ab99-9bc200ffed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translate(text: str) -> str:\n",
    "    # Перевод RU - EN\n",
    "    encoded = ru_en_tokenizer.prepare_seq2seq_batch([text], return_tensors=\"pt\").to(device)\n",
    "    translated = ru_en_model.generate(**encoded)\n",
    "    en_text = ru_en_tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "    # Перевод EN - RU\n",
    "    encoded_back = en_ru_tokenizer.prepare_seq2seq_batch([en_text], return_tensors=\"pt\").to(device)\n",
    "    translated_back = en_ru_model.generate(**encoded_back)\n",
    "    ru_text = en_ru_tokenizer.decode(translated_back[0], skip_special_tokens=True)\n",
    "    \n",
    "    return ru_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "pdlK_unp1q0r",
   "metadata": {
    "id": "pdlK_unp1q0r"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def augment_class_with_backtranslation(df: pd.DataFrame, label: int, n_aug: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Аугментирует тексты выбранного класса с помощью back-translation.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame с колонками 'text' и 'label'\n",
    "        label: целевой класс, который надо аугментировать\n",
    "        n_aug: сколько новых примеров создать на 1 оригинальный\n",
    "    \n",
    "    Returns:\n",
    "        Новый DataFrame с аугментированными строками\n",
    "    \"\"\"\n",
    "    df_target = df[df[\"label\"] == label]\n",
    "    augmented_rows = []\n",
    "\n",
    "    for _, row in tqdm(df_target.iterrows(), total=len(df_target)):\n",
    "        for _ in range(n_aug):\n",
    "            try:\n",
    "                aug_text = back_translate(row[\"text\"])\n",
    "                augmented_rows.append({\n",
    "                    \"text\": aug_text,\n",
    "                    \"label\": label\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(\"Ошибка при аугментации:\", e)\n",
    "\n",
    "    df_aug = pd.DataFrame(augmented_rows)\n",
    "    return df_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8d1c9989-6c9e-41cd-ad60-cb30aa455c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 172/172 [28:49<00:00, 10.05s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 492/492 [41:07<00:00,  5.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# Аугментируем label == 2, создавая 3 новых примера на каждый\n",
    "df_aug_2 = augment_class_with_backtranslation(df_clean, label=2, n_aug=3)\n",
    "df_aug_5 = augment_class_with_backtranslation(df_clean, label=5, n_aug=2)\n",
    "\n",
    "df_combined = pd.concat([df_clean, df_aug_2, df_aug_5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9f677eb-f69f-47df-92e9-7c944258d234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11572, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.read_csv('df_combined.csv')\n",
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "806a023e-5533-4193-999f-8aaf85b9f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"sberbank-ai/ruBert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4129ae9a-630e-41e7-b7fb-f09da110afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_combined[\"text\"].values,\n",
    "    df_combined[\"label\"].values,\n",
    "    test_size=0.25,\n",
    "    stratify=df_combined[\"label\"].values,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_encodings = tokenize_texts(X_train)\n",
    "test_encodings = tokenize_texts(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8d74f64-fbd8-4751-a3fd-bc198b10e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим баланс классов в лосс\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe42b08a-0912-4126-8bbc-8417ce400ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sberbank-ai/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class TicketDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TicketDataset(train_encodings, y_train)\n",
    "test_dataset = TicketDataset(test_encodings, y_test)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(np.unique(df_combined['label']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "737fb933-d385-4f33-83e7-0f26522818aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████| 543/543 [04:53<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss = 189.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|███████████████████████████████████████████████████████████████████████| 543/543 [05:07<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train loss = 37.9990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████████████████████████████████████████████████████████| 543/543 [05:12<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train loss = 19.0850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|███████████████████████████████████████████████████████████████████████| 543/543 [05:14<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train loss = 10.4725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|███████████████████████████████████████████████████████████████████████| 543/543 [05:16<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train loss = 10.7411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: train loss = {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "119722a5-7c84-43ae-9b48-3d0a04316bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total inference time: 26.07 seconds\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # оценка\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_logits = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "        all_logits.extend(logits.cpu().numpy())\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n Total inference time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67173e06-89dd-4565-a574-2c6350d273fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1024\n",
      "           1       0.94      0.97      0.95        93\n",
      "           2       0.99      1.00      1.00       172\n",
      "           3       0.98      1.00      0.99       107\n",
      "           4       0.99      0.96      0.97       483\n",
      "           5       1.00      0.99      1.00       369\n",
      "           6       0.98      1.00      0.99       182\n",
      "           7       0.96      0.95      0.96        83\n",
      "           8       0.97      0.94      0.96        81\n",
      "           9       0.98      1.00      0.99       299\n",
      "\n",
      "    accuracy                           0.99      2893\n",
      "   macro avg       0.98      0.98      0.98      2893\n",
      "weighted avg       0.99      0.99      0.99      2893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nclassification_report:\")\n",
    "\n",
    "target_names = [str(cls) for cls in np.unique(df_combined['label'])]\n",
    "print(classification_report(all_labels, all_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "67be9351-2dee-4738-a755-c53c1c376cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gpt\\\\tokenizer_config.json',\n",
       " './gpt\\\\special_tokens_map.json',\n",
       " './gpt\\\\vocab.txt',\n",
       " './gpt\\\\added_tokens.json',\n",
       " './gpt\\\\tokenizer.json')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"./gpt\"\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64011c3-e42a-4003-b035-f93fbaddd9cd",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "- Аугментация текстов для редких классов привела к улучшению качества классификации именно по этим классам. Критически малочисленные классы (1 и 5) теперь демонстрируют идеальные показатели, что снижает риск переобучения на доминирующих классах.\n",
    "\n",
    "- При этом общая точность и показатели по остальным классам не ухудшились — модель сохранила высокую эффективность.\n",
    "\n",
    "- Таким образом, применение аугментации (вместе с использованием class_weights) помогает сделать модель более сбалансированной по метрикам, особенно для редких классов, что может быть очень важным на практике, когда важно распознавать даже самые редкие ситуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb8edf9-adac-466d-81e0-a1475041c834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
