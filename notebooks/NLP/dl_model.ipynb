{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d1409-f638-4d23-88f5-029cde30d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o1r7IXXho2jh",
   "metadata": {
    "id": "o1r7IXXho2jh"
   },
   "source": [
    "# Deep Seek model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee4ae2a-281b-44ad-ab34-58492adfe246",
   "metadata": {
    "id": "6ee4ae2a-281b-44ad-ab34-58492adfe246"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import ast\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2de9bff-67c6-45b1-9087-f36e65cab1ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "b2de9bff-67c6-45b1-9087-f36e65cab1ce",
    "outputId": "c83d9e60-3de5-4a74-ffad-a59f896df08a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts_cmb</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['жалоба', 'абонент', 'просьба', 'ответ', 'зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['жалоба', 'абонент', 'абонент', 'утверждать',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['жалоба', 'абонент', 'абонент', 'утверждать',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['жалоба', 'абонент', 'абонент', 'утверждать',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['жалоба', 'абонент', 'абонент', 'утверждать',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>['жалоба', 'абонент', 'абонент', 'утверждать',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>['жалоба', 'абонент', 'абонент', 'утверждать',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10269</th>\n",
       "      <td>['сбой', 'активация', 'просьба', 'помочь', 'ре...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10270</th>\n",
       "      <td>['жалоба', 'абонент', 'абонент', 'утверждать',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10271</th>\n",
       "      <td>['жалоба', 'абонент', 'абонент', 'утверждать',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10072 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts_cmb  cluster\n",
       "0      ['жалоба', 'абонент', 'просьба', 'ответ', 'зап...        1\n",
       "1      ['жалоба', 'абонент', 'абонент', 'утверждать',...        0\n",
       "2      ['жалоба', 'абонент', 'абонент', 'утверждать',...        0\n",
       "3      ['жалоба', 'абонент', 'абонент', 'утверждать',...        0\n",
       "4      ['жалоба', 'абонент', 'абонент', 'утверждать',...        0\n",
       "...                                                  ...      ...\n",
       "10267  ['жалоба', 'абонент', 'абонент', 'утверждать',...        0\n",
       "10268  ['жалоба', 'абонент', 'абонент', 'утверждать',...        0\n",
       "10269  ['сбой', 'активация', 'просьба', 'помочь', 'ре...        2\n",
       "10270  ['жалоба', 'абонент', 'абонент', 'утверждать',...        0\n",
       "10271  ['жалоба', 'абонент', 'абонент', 'утверждать',...        0\n",
       "\n",
       "[10072 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../../tasks_support_system_ai/notebooks/NLP/labelled_data_1.csv')\n",
    "df.drop(columns=['Unnamed: 0.1', 'Column1', 'Unnamed: 0', 'topic'], inplace=True)\n",
    "df.drop(df[df.cluster == '?'].index, inplace=True)\n",
    "df = df[df['cluster'].notna()]\n",
    "df['cluster'] = df['cluster'].astype(int) - 1\n",
    "df = df[['texts_cmb', 'cluster']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c33595-6bae-4bc7-8dbe-22d6f5201674",
   "metadata": {
    "id": "87c33595-6bae-4bc7-8dbe-22d6f5201674"
   },
   "outputs": [],
   "source": [
    "df[\"texts\"] = df[\"texts_cmb\"].apply(lambda x: \" \".join(ast.literal_eval(x)))\n",
    "df.drop(columns= ['texts_cmb'], inplace=True)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93027d3-b27f-49d9-84cb-8ff9dbdf6dce",
   "metadata": {},
   "source": [
    "### Предобученная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0296aa59-eeb8-4b3a-8804-d8be35e5d9bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "id": "0296aa59-eeb8-4b3a-8804-d8be35e5d9bf",
    "outputId": "d65200e4-4a12-4feb-c634-0035cd096dda"
   },
   "outputs": [],
   "source": [
    "model_name = \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float32\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f58334fa-3931-487c-a915-a8ed056746ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaModel(\n",
       "  (embed_tokens): Embedding(32256, 2048)\n",
       "  (layers): ModuleList(\n",
       "    (0-23): 24 x LlamaDecoderLayer(\n",
       "      (self_attn): LlamaAttention(\n",
       "        (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "        (k_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "        (v_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "        (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "      )\n",
       "      (mlp): LlamaMLP(\n",
       "        (gate_proj): Linear4bit(in_features=2048, out_features=5504, bias=False)\n",
       "        (up_proj): Linear4bit(in_features=2048, out_features=5504, bias=False)\n",
       "        (down_proj): Linear4bit(in_features=5504, out_features=2048, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "      (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       "  (norm): LlamaRMSNorm((2048,), eps=1e-06)\n",
       "  (rotary_emb): LlamaRotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fafccf76-1eb0-4992-865b-c8fddc21484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = df[\"cluster\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d906f4b6-d674-4325-bb8c-1f9a0a472bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDeepSeekClassifier(nn.Module):\n",
    "    def __init__(self, base_model, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        dtype = next(base_model.parameters()).dtype  # Автоопределение типа\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.norm = nn.LayerNorm(hidden_size).to(dtype)  # стабилизация\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes).to(dtype)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        last_hidden_state = outputs.hidden_states[-1]\n",
    "        cls_rep = last_hidden_state[:, 0, :]\n",
    "        cls_rep = self.dropout(cls_rep)\n",
    "        cls_rep = self.norm(cls_rep)\n",
    "        logits = self.classifier(cls_rep)\n",
    "\n",
    "        loss = F.cross_entropy(logits.float(), labels.long())\n",
    "        return {\"loss\": loss, \"logits\": logits}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45ce5b9d-49c2-4e01-bfa5-05a940285bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ClusterDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(self.encodings[\"input_ids\"][idx]),\n",
    "            \"attention_mask\": torch.tensor(self.encodings[\"attention_mask\"][idx]),\n",
    "            \"labels\": torch.tensor(self.labels[idx])\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3cad04a-702a-41e9-bdef-80e91de972c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input_ids, attention_mask, labels=labels)\n",
    "        logits = output['logits']\n",
    "        loss = output['loss']\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            output = model(input_ids, attention_mask, labels=labels)\n",
    "            logits = output['logits']\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(classification_report(all_labels, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ebd890f-7e30-4632-8fa0-fb25ab40f9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 1.6373\n",
      "Epoch 2\n",
      "Train Loss: 1.3904\n",
      "Epoch 3\n",
      "Train Loss: 1.2976\n",
      "Epoch 4\n",
      "Train Loss: 1.2356\n",
      "Epoch 5\n",
      "Train Loss: 1.1873\n",
      "Epoch 6\n",
      "Train Loss: 1.1344\n",
      "Epoch 7\n",
      "Train Loss: 1.0957\n",
      "Epoch 8\n",
      "Train Loss: 1.0626\n",
      "Epoch 9\n",
      "Train Loss: 1.0347\n",
      "Epoch 10\n",
      "Train Loss: 1.0101\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ClusterDataset(train_df[\"texts\"].tolist(), train_df[\"cluster\"].tolist(), tokenizer)\n",
    "test_dataset = ClusterDataset(test_df[\"texts\"].tolist(), test_df[\"cluster\"].tolist(), tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CustomDeepSeekClassifier(base_model, hidden_size=2048, num_classes=df[\"cluster\"].nunique())\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76802baa-1c34-4b32-8712-2619c70cf6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74       787\n",
      "           1       0.92      0.65      0.76        34\n",
      "           2       0.57      0.13      0.22        90\n",
      "           3       0.84      0.49      0.62       413\n",
      "           4       1.00      0.41      0.58        95\n",
      "           5       1.00      0.09      0.17       128\n",
      "           6       1.00      0.12      0.21        69\n",
      "           7       0.94      0.47      0.63        72\n",
      "           8       0.96      0.88      0.92       246\n",
      "           9       0.79      0.56      0.65        81\n",
      "\n",
      "    accuracy                           0.68      2015\n",
      "   macro avg       0.86      0.48      0.55      2015\n",
      "weighted avg       0.77      0.68      0.64      2015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f77518-7e35-440d-86d2-2d90bf0ce29a",
   "metadata": {},
   "source": [
    "- Модель в целом делает предсказания с разумной точностью на уровне 68%, что приемлемо для многоклассовой задачи с 10 кластерами, но есть явные зоны для улучшения.\n",
    "\n",
    "- Некоторые классы сильно преобладают по количеству примеров (например, класс 0 — 787, класс 1 — 34), что влияет на метрики:\n",
    "\n",
    "    - Класс 0: высокая полнота (recall = 1.00) — модель почти всегда предсказывает его, но точность (precision = 0.58) невысока — много ложных срабатываний.\n",
    "\n",
    "    - Классы 5, 6: высокие precision (1.00), но очень низкий recall (0.09, 0.12) — модель почти не предсказывает эти классы, но когда предсказывает, попадает точно.\n",
    "    - Класс 2: низкие все метрики — f1 = 0.22, модель почти не умеет его находить.\n",
    "\n",
    "    - Классы 5, 6: такие же проблемы — плохой recall, очень мало обнаруженных случаев.\n",
    "\n",
    "\n",
    "**Рекомендации по улучшению:**\n",
    "\n",
    "- Применить class weights в CrossEntropyLoss или WeightedRandomSampler в DataLoader. Увеличить количество эпох обучения\n",
    "\n",
    "- Аугментация малых классов или oversampling.\n",
    "\n",
    "- Fine-tune или использовать scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34ee7944-babd-484e-a408-34e6ea04ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_path = \"../../../tasks_support_system_ai/notebooks/NLP\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "torch.save(model, os.path.join(save_path, \"full_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debba659-1b8c-4e94-a52e-b5752d643b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float32\n",
    ")\n",
    "\n",
    "model = CustomDeepSeekClassifier(base_model, hidden_size=2048, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, \"pytorch_model.bin\")))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d02319-c4d2-43a7-a8fc-5f772e955d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(os.path.join(save_path, \"full_model.pt\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c321702-25a6-4033-b076-a2c24d3643bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3]\n"
     ]
    }
   ],
   "source": [
    "def classify_texts(texts: list[str], model, tokenizer, device):\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, return_tensors=\"pt\", max_length=128)\n",
    "    input_ids = encodings[\"input_ids\"].to(device)\n",
    "    attention_mask = encodings[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=torch.zeros(len(texts)).long().to(device))\n",
    "        logits = outputs[\"logits\"]\n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return predictions\n",
    "\n",
    "texts = [\"Жалоба\", \"Заведите номер в blacklist\"]\n",
    "preds = classify_texts(texts, model, tokenizer, device)\n",
    "print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151fee6-b37c-4e2a-8711-1d5a41ef6544",
   "metadata": {
    "id": "7151fee6-b37c-4e2a-8711-1d5a41ef6544"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab9b9c-487e-4c8e-a072-2d191e977da0",
   "metadata": {
    "id": "2cab9b9c-487e-4c8e-a072-2d191e977da0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c02893a-2597-4f75-bbca-6bdc053d6dc3",
   "metadata": {
    "id": "7c02893a-2597-4f75-bbca-6bdc053d6dc3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c645b-a821-418c-b42b-729e6ac976cb",
   "metadata": {
    "id": "dd3c645b-a821-418c-b42b-729e6ac976cb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V6E1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
