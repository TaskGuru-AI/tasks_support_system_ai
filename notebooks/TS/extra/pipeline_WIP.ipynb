{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from darts import concatenate, TimeSeries\n",
    "from darts.dataprocessing.transformers import MinTReconciliator  # noqa\n",
    "from darts.metrics import mae, rmse, mape  # noqa\n",
    "from darts.models import (\n",
    "    LinearRegressionModel,\n",
    "    NaiveSeasonal,\n",
    "    ExponentialSmoothing \n",
    "\n",
    ")\n",
    "from darts.utils.model_selection import train_test_split\n",
    "from darts.utils.utils import ModelMode, SeasonalityMode\n",
    "from darts.utils.likelihood_models import GaussianLikelihood\n",
    "import matplotlib.pyplot as plt\n",
    "from tasks_support_system_ai.utils import get_correct_data_path\n",
    "from tasks_support_system_ai.readers import read_proper_ts_tree, ts_read_daily_tickets\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока не работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_df_slice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 147\u001b[0m\n\u001b[0;32m    135\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m    136\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_loader\u001b[39m\u001b[38;5;124m'\u001b[39m, DataLoader(data_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSUBRU\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mVSCodeProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtasks_support_system_ai\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtickets_daily\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtickets_daily.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m    137\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manomaly_detector\u001b[39m\u001b[38;5;124m'\u001b[39m, AnomalyDetector()),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    143\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_results\u001b[39m\u001b[38;5;124m'\u001b[39m, SaveResultsToCsv())\n\u001b[0;32m    144\u001b[0m ])\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Запускаем пайплайн\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Мы не передаем данные напрямую, потому что они загружаются в DataLoader\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SUBRU\\VSCodeProjects\\tasks_support_system_ai\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SUBRU\\VSCodeProjects\\tasks_support_system_ai\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:533\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;124;03m    Transformed samples.\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    532\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 533\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m last_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\SUBRU\\VSCodeProjects\\tasks_support_system_ai\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params)\u001b[0m\n\u001b[0;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\SUBRU\\VSCodeProjects\\tasks_support_system_ai\\.venv\\Lib\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SUBRU\\VSCodeProjects\\tasks_support_system_ai\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1314\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\SUBRU\\VSCodeProjects\\tasks_support_system_ai\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\SUBRU\\VSCodeProjects\\tasks_support_system_ai\\.venv\\Lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "Cell \u001b[1;32mIn[2], line 36\u001b[0m, in \u001b[0;36mAnomalyDetector.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdated_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m queue_id \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[1;32m---> 36\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mget_df_slice\u001b[49m(queue_id)  \u001b[38;5;66;03m# Применяем функцию для среза данных\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     outliers_fraction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m     38\u001b[0m     model \u001b[38;5;241m=\u001b[39m IsolationForest(contamination\u001b[38;5;241m=\u001b[39moutliers_fraction, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_df_slice' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from darts import TimeSeries\n",
    "from tasks_support_system_ai.utils import get_correct_data_path\n",
    "from tasks_support_system_ai.readers import read_proper_ts_tree, ts_read_daily_tickets\n",
    "from darts.models import LinearRegressionModel, NaiveSeasonal, ExponentialSmoothing\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# Кастомные классы для обработки данных\n",
    "class DataLoader(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Загрузка данных\n",
    "        df = ts_read_daily_tickets(self.data_path)\n",
    "        tree = read_proper_ts_tree(get_correct_data_path(\"custom_data/tree_proper.csv\"))\n",
    "        top_level_tree = tree[(tree[\"level\"] == 1) & (tree[\"full_load\"] != 0)]\n",
    "        top_level_queues = list(\n",
    "            top_level_tree[top_level_tree[\"full_load\"] >= 1300000][\"queueId\"].values\n",
    "        )\n",
    "        return top_level_queues\n",
    "\n",
    "class AnomalyDetector(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # Для каждого элемента в X (каждая очередь), находим аномалии с помощью IsolationForest\n",
    "        self.updated_data = {}\n",
    "        for queue_id in X:\n",
    "            result = get_df_slice(queue_id)  # Применяем функцию для среза данных\n",
    "            outliers_fraction = 0.01\n",
    "            model = IsolationForest(contamination=outliers_fraction, random_state=42)\n",
    "            result[\"anomaly\"] = model.fit_predict(result[[\"new_tickets\"]])\n",
    "\n",
    "            # Заменяем аномалии линейной интерполяцией\n",
    "            result[\"new_tickets_interp\"] = result[\"new_tickets\"].copy()\n",
    "            result.loc[result[\"anomaly\"] == -1, \"new_tickets_interp\"] = np.nan\n",
    "            result[\"new_tickets_interp\"] = result[\"new_tickets_interp\"].interpolate(method=\"linear\")\n",
    "\n",
    "            self.updated_data[queue_id] = result\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Возвращаем уже обновленные данные\n",
    "        return self.updated_data\n",
    "\n",
    "class GridSearchForModels(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, models_to_try):\n",
    "        self.models_to_try = models_to_try\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.model_metrics = {}\n",
    "        for queue_id, data in X.items():\n",
    "            # Разделяем на обучающую и тестовую выборку\n",
    "            ts = TimeSeries.from_dataframe(\n",
    "                data,\n",
    "                value_cols=\"new_tickets_interp\",\n",
    "                fill_missing_dates=True,\n",
    "                fillna_value=0,\n",
    "                freq=\"D\",\n",
    "            )\n",
    "            X_train, X_test = train_test_split(ts, test_size=0.25)\n",
    "            model_metrics = {}\n",
    "\n",
    "            for model_name, model_class in self.models_to_try.items():\n",
    "                print(f\"Analyzing {model_name} for Queue {queue_id}...\")\n",
    "\n",
    "                # Для линейной регрессии\n",
    "                if model_name == \"Regression\":\n",
    "                    optimal_params = grid_search_regression(X_train, X_test)\n",
    "                    model = model_class(\n",
    "                        lags=sorted(optimal_params[1]['lags']),\n",
    "                        output_chunk_length=optimal_params[1]['output_chunk_length'],\n",
    "                        multi_models=optimal_params[1]['multi_models']\n",
    "                    )\n",
    "                elif model_name == 'Naive Seasonal':\n",
    "                    optimal_params = grid_search_naive_seasonal(X_train, X_test)\n",
    "                    model = model_class(K=optimal_params[1]['K'])\n",
    "                elif model_name == 'Exponential Smoothing':\n",
    "                    optimal_params = grid_search_ES(X_train, X_test)\n",
    "                    model = model_class(\n",
    "                        trend=optimal_params[1]['trend'],\n",
    "                        seasonal=optimal_params[1]['seasonal'],\n",
    "                        seasonal_periods=optimal_params[1]['seasonal_periods']\n",
    "                    )\n",
    "                else:\n",
    "                    model = model_class\n",
    "\n",
    "                model.fit(X_train)\n",
    "                X_pred = model.predict(60)\n",
    "\n",
    "                RMSE_score = rmse(X_pred, X_test)\n",
    "                MAE_score = mae(X_pred, X_test)\n",
    "                MAPE_score = mape(X_pred, X_test)\n",
    "                model_metrics[model_name] = (RMSE_score, MAE_score, MAPE_score)\n",
    "\n",
    "            self.model_metrics[queue_id] = model_metrics\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Возвращаем метрики для всех очередей\n",
    "        return self.model_metrics\n",
    "\n",
    "# Этап сохранения результатов\n",
    "class SaveResultsToCsv(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, filename=\"model_metrics.csv\"):\n",
    "        self.filename = filename\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = []\n",
    "        for queue_id, metrics in X.items():\n",
    "            for model_name, (rmse, mae, mape) in metrics.items():\n",
    "                data.append({\n",
    "                    \"Queue ID\": queue_id,\n",
    "                    \"Model\": model_name,\n",
    "                    \"RMSE\": rmse,\n",
    "                    \"MAE\": mae,\n",
    "                    \"MAPE\": mape\n",
    "                })\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(self.filename, index=False)\n",
    "        print(f\"Results saved to {self.filename}\")\n",
    "        return X\n",
    "\n",
    "# Строим пайплайн\n",
    "pipeline = Pipeline([\n",
    "    ('data_loader', DataLoader(data_path=\"tickets_daily.csv\")),\n",
    "    ('anomaly_detector', AnomalyDetector()),\n",
    "    ('grid_search', GridSearchForModels(models_to_try={\n",
    "        \"Regression\": LinearRegressionModel,\n",
    "        \"Naive Seasonal\": NaiveSeasonal,\n",
    "        \"Exponential Smoothing\": ExponentialSmoothing\n",
    "    })),\n",
    "    ('save_results', SaveResultsToCsv())\n",
    "])\n",
    "\n",
    "# Запускаем пайплайн\n",
    "results = pipeline.fit_transform(None)  # Мы не передаем данные напрямую, потому что они загружаются в DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
