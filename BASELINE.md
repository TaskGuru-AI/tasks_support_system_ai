# Baseline для Time Series

## Выводы Baseline:
### Описание построения Baseline:
Бейзлайн модель, выбранное после проведенных эксперементов, представляет собой линейную регрессию, которая пытается предсказать количество запросов (тикетов) в техническую поддержку на основе исторических данных. Так же были использованы NaiveSeasonal и ExponentialSmoothing для сравнения качества.

Процесс построения модели:
1. Данные: модель использует исторические данные по количеству тикетов за выбранный период для Топ 3 очередей по нагрзуке.
2. Предобработка данных: на предыдущем этапе удалось восстановить иерархию очередй. После того как нагрузка по каждой очереди получена, применяется IsolationForest для выявления аномалий, которые заменяются линейной интерполяцией.
3. Использование GridSearch для подбора гиперпараметров:
Для линейной регрессии настраиваются следующие параметры:

- lags: список случайных значений для лагов (число дней, которые используются для предсказания).
- output_chunk_length: диапазон возможных значений для длины выходных данных (например, прогноз на несколько дней вперед).
- multi_models: булевый параметр, указывающий, использовать ли несколько моделей для обучения.

Для модели Naive Seasonal настраиваются следующие параметры:

- K: диапазон возможных значений для параметра сезонности, который определяется как количество периодов сезонности в данных.

Для модели Exponential Smoothing настраиваются следующие параметры.

- trend: возможные варианты тренда — добавочный (additive), мультипликативный (multiplicative) или отсутствие тренда (none).
- seasonal: возможные варианты сезонности — добавочный, мультипликативный или отсутствие сезонности.
- seasonal_periods: диапазон возможных значений для периода сезонности (количество дней в одном сезоне).

4. Моделирование: применяется модели для прогнозирования количества тикетов на основе 30 дней (конкретные дни подбираются в процессе GridSearch)

### Мотивация выбора метрик: 
- Комплексная оценка модели с использованием MAE для стабильной и интерпретируемой оценки средней ошибки, RMSE для выявления моделей с большими ошибками и MAPE для оценки ошибок в относительных терминах, позволяет обнаруживать слабые места, такие как систематические ошибки, высокую вариацию и проблемы с небольшими значениями, обеспечивая баланс между интерпретируемостью и чувствительностью.



[Ноутбук с baseline](./notebooks/TS/baseline.ipynb)

# Baseline для NLP
## Выводы:
- Была проведена разметка данных для возможности обучения классификатора.
- Данные размечены по 10 классам:
  1. Списания/денежные средства
  2. Проблемы с сим-меню
  3. Esim (проблемы подключения, код активации, qr-код)
  4. Проблемы с контентом и отключение услуг/ подписок/ сервисов
  5. Учетные записи
  6. Уведомления о технических работах
  7. Сбой работы (в работе оператора)
  8. Тесты, проблемы с доставкой, прочие тех. оповещения
  9. Черный список
  10. Спам, реклама
- Написаны статьи для Википедии технической поддержки (https://disimhot.name/mediawiki/index.php/Esim)
- Обучена общая модель Word2Vec для тикетов и статей
- Данные были нормализованы, обучен классификатор SVM с подобранными по сетке параметрами
- Выбрана метрика accuracy - доля правильных ответов - для общей оценки качества выбранного классификатора. Метрика  Recall демонстрирует способность алгоритма обнаруживать данный класс, а precision — способность отличать этот класс от других классов.

[Ноутбук с baseline](./notebooks/NLP/Baseline.ipynb)
