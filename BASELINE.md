# Baseline для Time Series

## Выводы Baseline:
### Описание построения Baseline:
Бейзлайн модель, выбранное после проведенных эксперементов, представляет собой линейную регрессию, которая пытается предсказать количество запросов (тикетов) в техническую поддержку на основе исторических данных. Так же были использованы NaiveSeasonal и ExponentialSmoothing для сравнения качества.

Процесс построения модели:
1. Данные: модель использует исторические данные по количеству тикетов за выбранный период для Топ 3 очередей по нагрзуке.
2. Предобработка данных: на предыдущем этапе удалось восстановить иерархию очередй. После того как нагрузка по каждой очереди получена, применяется IsolationForest для выявления аномалий, которые заменяются линейной интерполяцией.
3. Использование GridSearch для подбора гиперпараметров
4. Моделирование: применяется модели для прогнозирования количества тикетов на основе 30 дней (конкретные дни подбираются в процессе GridSearch)

### Мотивация выбора метрик: 
- Комплексная оценка модели с использованием MAE для стабильной и интерпретируемой оценки средней ошибки, RMSE для выявления моделей с большими ошибками и MAPE для оценки ошибок в относительных терминах, позволяет обнаруживать слабые места, такие как систематические ошибки, высокую вариацию и проблемы с небольшими значениями, обеспечивая баланс между интерпретируемостью и чувствительностью.

### Результаты:
![image](https://github.com/user-attachments/assets/2485bef3-56c3-4c3c-9453-e149f90c878b)

Анализ результатов прогнозирования
![image](https://github.com/user-attachments/assets/2510ddda-5714-4cf3-8260-be50b53cb9c1)

Среди представленных моделей наилучшие результаты показала регрессионная модель, продемонстрировав минимальные значения ошибок: RMSE (281.40), MAE (208.37), и MAPE (9.05%). Наивная сезонная модель уступила регрессионной, но оказалась лучше экспоненциального сглаживания, с RMSE (299.71), MAE (225.78), и MAPE (10.72%). Экспоненциальное сглаживание показало худшие результаты по абсолютным метрикам (RMSE: 321.10, MAE: 255.76). Рекомендуется использовать регрессионную модель как основную, учитывая её более высокую точность.

Различия в метриках моделей могут быть связаны с их способностью учитывать структуру временного ряда. Регрессионная модель, несмотря на отсутствие дополнительных признаков и учёта сезонности, продемонстрировала наилучшие результаты, возможно, благодаря лучшей адаптации к данным. Наивная сезонная модель показала средние результаты, так как учитывает только повторяющиеся сезонные паттерны, но игнорирует тренды и другие зависимости. Экспоненциальное сглаживание оказалось наименее точным, вероятно, из-за своей неспособности эффективно захватывать сложные изменения, присутствующие в данных. Отличия в результатах также могут быть связаны с шумами или нестабильностью во временном ряде.

[Ноутбук с baseline](./notebooks/TS/baseline.ipynb)

# Baseline для NLP
## Выводы:
- Была проведена разметка данных для возможности обучения классификатора.
- Данные размечены по 10 классам:
  1. Списания/денежные средства
  2. Проблемы с сим-меню
  3. Esim (проблемы подключения, код активации, qr-код)
  4. Проблемы с контентом и отключение услуг/ подписок/ сервисов
  5. Учетные записи
  6. Уведомления о технических работах
  7. Сбой работы (в работе оператора)
  8. Тесты, проблемы с доставкой, прочие тех. оповещения
  9. Черный список
  10. Спам, реклама
- Написаны статьи для Википедии технической поддержки (https://disimhot.name/mediawiki/index.php/Esim)
- Обучена общая модель Word2Vec для тикетов и статей
- Данные были нормализованы, обучен классификатор SVM с подобранными по сетке параметрами
- Выбрана метрика accuracy - доля правильных ответов - для общей оценки качества выбранного классификатора. Метрика  Recall демонстрирует способность алгоритма обнаруживать данный класс, а precision — способность отличать этот класс от других классов.

[Ноутбук с baseline](./notebooks/NLP/Baseline.ipynb)

![image](https://github.com/user-attachments/assets/d23a30de-d374-4887-9173-fdb3dcc2fdb4)

Анализ результатов SVM модели для многоклассовой классификации
![image](https://github.com/user-attachments/assets/75dc2ff5-d6f2-4fda-b57c-e8e77800e46f)

Классы с высокой точностью: Класс 1: Precision = 0.99, Recall = 0.98, F1-score = 0.98. Модель практически всегда правильно классифицирует примеры этого класса. Этот класс содержит наибольшее количество тикетов, что может объяснять высокую точность. Классы 6 и 9: Класс 6: Precision = 0.94, Recall = 0.93, F1-score = 0.93. Класс 9: Precision = 0.90, Recall = 0.88, F1-score = 0.89. Оба класса имеют хорошие результаты, что указывает на уверенную работу модели.

Классы со средней точностью: Класс 4: Precision = 0.77, Recall = 0.88, F1-score = 0.82. Несмотря на не самый высокий precision, модель хорошо классифиирует этого класса. Класс 5: Precision = 0.86, Recall = 0.83, F1-score = 0.85. Средняя точность, но приемлемые результаты. Класс 3: Precision = 0.75, Recall = 0.74, F1-score = 0.75. Значения сбалансированы, хотя точность и полнота могли бы быть выше.

Классы с низкой точностью: Класс 8: Precision = 0.67, Recall = 0.48, F1-score = 0.56. Низкий recall (0.48) говорит о том, что модель пропускает значительное количество примеров этого класса. Возможно, проблема связана с малым количеством данных или схожестью признаков с другими классами. Класс 10: Precision = 0.66, Recall = 0.42, F1-score = 0.52. Очень низкий recall, так что модель плохо классифицирует этот класс. Класс 2: Precision = 0.64, Recall = 0.73, F1-score = 0.68. Сравнительно низкая точность, хотя recall выше.

Общие выводы: Дисбаланс классов: Класс 1 содержит 40% тикетов, а некоторые другие классы, например, классы 2 (133) и 10 (283), содержат значительно меньше данных.

Такой дисбаланс влияет на производительность модели, так как алгоритм SVM часто уделяет больше внимания более частым классам.

Причины могут включать:

Плохое разделение признаков между этими классами и другими.
Малое количество данных в этих классах.
Macro average: Precision = 0.79, Recall = 0.77, F1-score = 0.77. Эти значения усредняют метрики по всем классам и показывают, что модель работает не идеально для редких классов. Weighted average: Precision = 0.88, Recall = 0.88, F1-score = 0.88. Взвешенные значения выше из-за большого количества примеров класса 1.

Таким образом, модель показывает хорошую производительность в целом, но требует доработки для редких классов (особенно классы 8 и 10). Использование взвешенных весов классов и оптимизация параметров поможет улучшить результаты.

