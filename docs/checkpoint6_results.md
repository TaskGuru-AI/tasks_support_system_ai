## Сравнение Метрик Моделей TS

| Метрики  | Baseline |    ML    |    DL    |
|----------|----------|----------|----------|
| RMSE     | 172.90   | 137.21   | 216.53   |
| MAE      | 130.73   | 68.33    | 189.34   |
| MAPE     | 13.05    | 0.35     | 104      |

Из таблицы видно, что на данный момент, бустинговые ML-модели демонстрируют превосходство в точности прогнозов. Для улучшения DL-моделей далее планируется провести более тщательный подбор архитектуры, включая количество слоев и параметров, а также эксперименты с различными стратегиями скорости обучения и регуляризации.


## Сравнение Метрик Моделей NLP

| Метрики | Linear | Boosting | DL       |
|---------|--------|---------|----------|
| ROC AUC | 0.935  |  0.984  | 0.998    |
| acc     | 0.75   |  0.88   | 0.97     |

---

### 1. [RuBERT_2_with_augs.ipynb](https://github.com/TaskGuru-AI/tasks_support_system_ai/blob/main/notebooks/NLP/RuBERT_2_with_augs.ipynb)

#### **Что сделано:**
- **Использована предобученная модель RuBERT** для классификации текстов.
- **Применены методы аугментации данных** (например, замены слов синонимами, случайные вставки/удаления) для увеличения размера обучающей выборки.
- **Настроен Fine-Tuning модели** на целевом датасете.
- **Проведена оценка качества** модели на тестовых данных с метриками: accuracy, precision, recall, F1-score.
- **Back-Translation** Текст переводился на английский и обратно с помощью opus-mt. Сохраняет смысл, но меняет формулировки. Это полезно для увеличения разнообразия синтаксиса.
#### **Результаты:**
- **Accuracy:** ~0.89 (на тестовой выборке).
- **F1-score (weighted):** ~0.88.
- **Вывод:** Аугментация данных помогла улучшить обобщающую способность модели, особенно на классах с малым количеством примеров.

---

### 2. [dl_model.ipynb](https://github.com/TaskGuru-AI/tasks_support_system_ai/blob/main/notebooks/NLP/dl_model.ipynb)

#### **Что сделано:**
- **Реализована нейросетевая модель** на основе DeepSeek для обработки текстов.
- **Использованы эмбеддинги** для векторного представления слов.
- **Обучение с применением Dropout и BatchNorm** для регуляризации.

#### **Результаты:**
- **Лучшая модель (DeepSeek + Dropout):**  
  - **Accuracy:** ~0.85.  
  - **F1-score:** ~0.84.  
- **Вывод:** Глубокая модель показала хорошие результаты, но уступила RuBERT в точности. Оптимальный выбор зависит от задач (скорость vs. качество).
