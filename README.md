# tasks_support_system_ai
Technical support task analysis system
    
Time Series
1 этап (разведочный анализ данных и первичная аналитика данных):
    
    ● Подготовка данных:
        ○ Очистка данных
        ○ Если данные формата заявка в момент времени, то надо сагрегировать до удобных промежутков (пятиминутки, к примеру) и кол-ва запросов.
        ○ Прогнать ADF тест, выполнить дифференцирование, чтобы получить стационарный ряд
    ● Базовый EDA:
        ○ Анализ доступных признаков (внешние факторы), создание лагов,
        скользящих статистик, анализ их влияния на целевую переменную.
        ○ Какие присутствуют тренды, сезональность
        ○ Анализ среднего, стандартного отклонения, автокорреляция
        ○ Какой календарь влияет на целевую переменную (выходные,
        праздники РФ и другие)
    ● Валидация данных:
        ○ Есть ли пропуски
        ○ Анализ аномалий
    ● Визуализация данных
    ● Корректное разбиение на train/validation/test для последующего обучения моделей
    ● Выбор метрики для оценки качества (MAE, RMSE, MAPE, sMAPE, MASE и другие). Отдельно, возможно, метрики качества техподдержки (как SLA)
    ● Построение бейзлайна через T-1 день, T-1 шаг, линейная регрессия, k-NN, решающее дерево, случайный лес.
2 этап (ML)
    
    ● Использование градиентного бустинга, ARIMA моделей, Prophet, Neural Prophet
    ● Написание цикла/функции для эффективного тестирования и
    экспериментирования
    ● Сравнение качества и скорости моделей, подбор гиперпараметров
    ● Визуализация предсказаний с доверительным интервалом, сравнение с реальными данными, интерпретация модели
    ● Feature importance модели, если возможно 3 этап (DL)
    ● В разделе “что хочется сделать, но не обязательно успеем” 
    
NLP
1 этап (разведочный анализ данных и первичная аналитика данных):
    
    ● Базовый EDA :
        ○ Определение количества уникальных и часто встречаемых слов
        ○ Определение количества стоп-слов
        ○ Оценка разнообразия словарного запаса
        ○ Очистка данных (наличие ошибок, ненормализованные символы)
        ○ Анализ n - грамм
    ● Оценить количество возможных кластеров по данным
        ○ Метод “локтя”
        ○ Метод “силуэта” 
2 этап (ML)
    
    ● Векторизация, использование эмбеддингов - TF-IDF, Bag of Words (BoW), Word2Vec.
    ● Оценка метрик 
        ○ Точность
        ○ Полнота
        ○ F-мера
    ● Применение токенизации, стемминга и лемматизации.
    ● Применение моделей ML для кластеризации.
        ○ LogReg
        ○ Random Forest
        ○ K-Means
        ○ DBScan
    ● Анализ результатов кластеризации. Сравнение моделей.
        ○ Проверка устойчивости к изменению данных
        ○ Выявление шумов
        ○ Определение ключевых “слов” (признаков) для кластеров
3 этап (DL)
    
    ● Анализ и выбор архитектуры нейронной сети (LSTM, Transformers)
    ● Обучение модели
        ○ Определение функции потерь
        ○ Определние оптимизатора
        ○ Предотвращение переобучения (Регуляризация)
    ● Обучение модели на данных
    ● Оценка модели
        ○ Выбор подходящих метрик 
    ● Настройка гиперпараметров
        ○ Сравнение различных способов настройки 
    ● Тест модели на новых данных
Общее

    Инженерная составляющая:
    
    ● Микросервис, поднимаемый через Docker Compose
    ● Графики и элементы взаимодействия отображаются в streamlit 
Как хотелось бы, чтобы выглядела система, будет обновляться:

Общее:

    ● Выбор базы знаний для авторекомендаций, парсинг/ обработка.
    ● Сравнение “лучшей DL модели” и “лучшей ML модели” с другими вариантами для каждой из выполненных задач, анализ результатов

То что хочется сделать, но не обязательно успеем:
    
    ● Применение DL в прогнозировании временных рядов: GRU, LSTM
    ● Выдача релевантной вики-страницы по тексту обращения
    ● Использование локальной LLM для кластеризации обращений
    ● Прогнозирование и кластеризация обращений не только исторических
    данных, но и в режиме реального времени через API запросы.
    ● Генерация фиктивных тикетов с различной частотой, чтобы оценить
    адаптивность системы к новым условиям
    ● Телеграм-бот для регистрации обращений от пользователей
    ● Дообучение модели предсказания нагрузки в процессе инференса и
    бесшовное обновление
    ● Определение тональности заявок для оценки срочности и приоритета
    обработки
    ● Выявление зависимости между тональностью и временем решения задачи
