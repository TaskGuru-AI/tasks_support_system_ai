## 19. Система анализа задач службы технической поддержки с авторекомендациями.

**Куратор** - Руслан Каюмов @KayumovRu

**Участники**:
- Ермаков Павел Алексеевич @Patapon
- Ефимова Елена Сергеевна @ElenaSergeevna
- Рудаш Кирилл Андреевич @KirillKirilych
- Филоненко Феодосия Юрьевна @andiefreude
- Ильин Илья Владимирович @ilyinily

Проект включает в себя прогнозирование временных рядов и NLP , направлен на разработку системы, которая будет анализировать данные о прошлых обращениях в службу поддержки и предоставлять прогнозы о будущих обращениях.

Прогнозирование временных рядов позволит предсказывать количество и характер обращений клиентов в будущем, что поможет лучше планировать ресурсы и предотвращать возможные проблемы. Это может включать в себя анализ трендов и других факторов, влияющих на частоту и тип обращений.

NLP же позволит системе понимать и обрабатывать текстовые данные, такие как описания проблем и запросы пользователей. С помощью NLP можно будет автоматически классифицировать обращения, извлекать ключевые слова и фразы, а также определять тональность и контекст сообщений.

Наш проект разделен на 2 части (TS, NLP), и для 2 частей мы используем разные датасеты.

## Особенности TS

- Нагрузка на очереди имеет иерархическую структуру. Одна очередь может иерархически иметь глубину - 6 очередей. И ожидается, что клиента будет интересовать нагрузка на конкретную очередь, но при этом мы должны включать все дочерние очереди.

## Особенности NLP

- В датасете есть много сокращений и слов на английском языке, которые были предобрабатывались для кластеризации. В стоп-слова добавлены слова, которые ухудщали coherence score.

## Файлы с выводами

- [checkpoints, описание чекпоинтов](./checkpoints.md)
- [dataset, описание данных](./dataset.md)
- [EDA, анализ данных](./EDA.md)
- [baseline, Описание базовых моделей](./BASELINE.md)
- здесь будет `report.pdf` с более подробным рассказом, чем мы занимались

## Сервис

### Frontend

Сервис написан на фреймворке Streamlit. В нем есть две страницы - для NLP и TS.

###  Backend

Вебсервис реализован на веб-фреймворке FastAPI.

### Запуск

Так как фронтенд и бэкенд почти всегда запускаются вместе, то для локального запуска используется `docker compose up backend frontend -d --build` или `just service-build`
Фронтенд будет находиться на локальном порту `http://0.0.0.0:8501/`

## Инфраструктура

### Перед запуском

- Чтобы скачать данные, надо указать логин, пароль от инстанса MiniO в `.env` (в беседе)
- Установить `poetry`
- Запустить `poetry install`
- Установить `just` для удобства

### Структура кода

- `data/` - данные проекта, подгружаются отдельной командой
- `notebooks/` - ноутбуки с исследованием данных, качества моделей (TS + NLP)
- `scripts/` - полезные скрипты (может их перенести внутрь tasks_support_system_ai?)
- `tasks_support_system_ai/` - пакет со всем функционалом, который будет использоваться для работы сервиса
- `tasks_support_system_ai/service/` - код для сервиса (back + front)
- `tests/` - тесты пакета
- `docker/nginx/conf.d/` - конфиг для `nginx` при запуске `miniO` для хранения и обмена данными

### Данные

- Данные лежат в инстансе MiniO, куда можно пушить и откуда пуллить данные через `just pull-data` и `just push-data`.
- Инстанс поднимается через `docker compose`, код которого находится в данном репозитории.

### Контроль качества кода

- Настроена автопроверка тестов, правил линтера и форматтера.
- В качестве линтера и форматтера используется `ruff`. Используется большое кол-во правил.
- Для автоисправления локально можно использовать рецепт `just full-style`.

### Особенности

- Используем `just` для запуска частых команд. Он похож на `make`, но удобней из-за специализации не на сборке, а на запуске команд.
- Зависимости устанавливаем через `poetry`
- Папка `./tasks_support_system_ai/` - это python пакет, который устанавливается в окружение через `poetry`. Это помогает значительно облегчить жизнь с импортами модулей внутри пакета.
